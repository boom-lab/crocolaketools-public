## CrocoLakeTools

CrocoLakeTools is a Python package containing modules to interface with CrocoLake -- a database of oceanographic observations that is developed and maintained in the framework of the NSF-sponsored project CROCODILE (CESM Regional Ocean and Carbon cOnfigurator with Data assimilation and Embedding).

It is composed of two submodules, `downloader` and `converter`, which retrieve the most recent version of some ocean observations datasets and convert them to CrocoLake's format. It share some utilities with [CrocoLakeLoader](https://github.com/boom-lab/crocolakeloader/tree/9758ba72f1d6fc968a5cfabf8740a49eef9022ea), the package to load and manipulate CrocoLake's data, and it is included as a submodule.

### Table of Contents
1. [Installation](#installation)
2. [Converting datasets and building CrocoLake](#converting-datasets-and-building-crocolake)
3. [converter](#converter)
4. [downloader](#downloader)
5. [Available sources](#available-sources)

### Installation
Clone the repository locally with its submodules:
```
git clone --recursive git@github.com:boom-lab/crocolaketools-public.git
```
Install it with pip:
```
cd crocolaketools-public
pip install ./crocolakeloader/
pip install .
```

If you encounter some dependency issues, try running
```
pip install ./crocolakeloader/
pip install . -c constraints.txt
```

### Converting datasets and building CrocoLake
To test that the code executes succesfully and to have an idea of how the converters work, first download the demo data:
```
download_demo_data
```

This will set up the folder `./crocolaketools/demo/` and store the demo data in there by converter (e.g. `./crocolaketools/demo/demo_GLODAP/`, `./crocolaketools/demo/demo_ARGO_GDAC/`).

Generally, you can run a converter with a command that looks like
```
<converter_script> --config
```
Where `<converter_script>` depends on the converter (e.g. `glodap2parquet`, `argo2argoqc_phy`) amd the `--config` flag tells the script to read the paths and flags from the config file `./crocolaketools/config/config.yaml`. The file is set up to run with the demo data and you can adjust it as you prefer.

Some scripts are provided in the `scripts` folder to illustrate how one can generate their own version The steps below illustrate how to run each converter.

#### Argo GDAC

To convert the original Argo data stored as in the Argo GDAC, run:
```
./argogdac2parquet.sh
```
This converter behaves differently from the others because of some legacy architecture. Note that the converter requires the original data to be stored in the same directory structure as in the Argo GDAC. `argo_dl.sh` shows how to download the data to preserve such directory structure (it should download the same data used for the demo).

#### Argo QC

This dataset requires a parquet copy of the original Argo data from the GDAC, in other words it requires Argo data in parquet as generated by `argogdac2parquet.sh`. The demo data already contains a converted copy. To execute the converter, run:
```
argo2argoqc_phy --config
```
or
```
argo2argoqc_bgc --config
```
for the physical and biogeochemical dataset, respectively.

#### GLODAP and Spray Gliders

For these datasets, you can run
```
glodap2parquet --config
spray2parquet --config
```
and both physical and biogeochemical parquet versions are generated.

#### CrocoLake

Once you have two or more dataset in the parquet version, you can build CrocoLake running:
```
merge_crocolake -d <var> --config
```
where you replace `<var>` with `PHY` for the physical version, and with `BGC` for the biogeochemical version. The `config.yaml` identifies all the paths where the script will look for the parquet datasets. The script merges them into a unified dataset.

### `converter`

The `converter` module contains several classes to convert from one source to the parquet format; they all inherit from the `Conveter()` class and follow the same workflow, but each step can be highly specialized depending on the observations source. For GLODAP and Spray Gliders data, it requires that the machine hosts the original sources. The examples in the `scripts` folder to show how to set up and run an existing converter.

### `downloader`

The `downloader` module downloads the observations sources to convert. It currently contains tools to download Argo's GDAC only.

### Available sources

As of this release, CrocoLake includes all the [Argo](https://argo.ucsd.edu/) physical and biogeochemical data present in the GDAC, [GLODAP](https://glodap.info/)'s database, and QC-ed observations from [Spray Gliders](https://spraydata.ucsd.edu/about/spray-glider).

We are always working on including new sources, and the next candidates are the [North Atlantic CPR Survey](https://www.bco-dmo.org/project/547835) and the [Oleander project](https://www.aoml.noaa.gov/phod/goos/oleander/intro.php).

If you are interested in a particular dataset to be added, [get in touch](enrico.milanese@whoi.edu)!
